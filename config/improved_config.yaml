# Improved cGAN Configuration
# Architecture: WGAN-GP + Spectral Norm + Residual Blocks + Self-Attention

model:
  architecture: improved
  latent_dim: 128
  embed_dim: 64
  generator_base_channels: 128    # Reduced from 256 — fewer channels = smaller gradients
  discriminator_base_channels: 64
  use_self_attention: true
  use_residual: true

training:
  batch_size: 64
  num_epochs: 100
  lr_g: 0.00005    # Reduced from 0.0001 — key fix for explosion
  lr_d: 0.0002     # Reduced from 0.0004 — key fix for explosion
  beta1: 0.0       # WGAN-GP standard
  beta2: 0.9
  n_critic: 5
  gp_lambda: 10
  loss_type: "wgan-gp"
  grad_clip: 1.0   # NEW: gradient clipping as safety net

data:
  num_classes: 10
  image_size: 32
  seed: 42
  num_workers: 2

hyperparameter_search:
  lr_g_tried: [0.0002, 0.0001, 0.00005]
  lr_d_tried: [0.0004, 0.0002]
  best_config: "lr_g=0.00005, lr_d=0.0002, base_channels=128"
