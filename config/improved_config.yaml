# Improved cGAN Configuration (v9)
# Architecture: SN-GAN style with hinge loss.
#
# v6-v8 all produced saturated color blocks due to three compounding issues:
#   1. G-favored TTUR (lr_g=2×lr_d) starved D of learning capacity
#   2. R1 penalty (gamma=2.0) actively suppressed D's gradients on real data,
#      causing Real→Real accuracy to drop below 50%
#   3. D base_channels=48 was too small for reliable feature extraction
#
# v9 fixes:
#   - D-favored TTUR (lr_d=4×lr_g), matching BigGAN standard
#   - R1 disabled (SN + hinge is sufficient for stability)
#   - D base_channels restored to 64 for adequate capacity
#   - n_critic=2 to give D extra training (BigGAN standard)
#   - Generator: SN only on final conv + no ReLU (structural anti-saturation)

model:
  architecture: improved
  latent_dim: 128
  embed_dim: 64
  generator_base_channels: 256
  discriminator_base_channels: 64    # Restored from 48 — D needs capacity to learn
  use_self_attention: true
  use_residual: true

training:
  batch_size: 128
  num_epochs: 200
  # D-favored TTUR (BigGAN standard: D learns 4× faster than G)
  lr_g: 0.0001
  lr_d: 0.0004
  beta1: 0.0
  beta2: 0.999               # BigGAN uses 0.999 (was 0.9)
  n_critic: 2                 # Train D twice per G step (BigGAN standard)
  loss_type: "hinge"
  grad_clip: 0.0

  # EMA
  ema_decay: 0.999

  # Cosine LR scheduling
  lr_schedule: "cosine"

  # Instance noise
  d_noise_std: 0.1
  d_noise_decay_epochs: 100

  # R1 gradient penalty: DISABLED. R1 penalizes ||∇D(real)||², which
  # actively suppresses D's confidence on real data. This caused
  # Real→Real accuracy to drop below 50% in v6-v8. SN + hinge loss
  # already provides sufficient Lipschitz regularization.
  r1_gamma: 0.0
  r1_every: 16

data:
  num_classes: 10
  image_size: 32
  seed: 42
  num_workers: 2
